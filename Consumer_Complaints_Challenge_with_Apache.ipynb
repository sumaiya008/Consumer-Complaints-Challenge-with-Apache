{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Consumer Complaints Challenge with Apache\n",
        "\n",
        "We are greatly inspired by the [Consumer Complaints](https://github.com/InsightDataScience/consumer_complaints) challenge from [InsightDataScience](https://github.com/InsightDataScience/). In fact, we are going to tackle the same challenge but using Apache Spark. Please read through the challenge at the following link:\n",
        "\n",
        "<https://github.com/InsightDataScience/consumer_complaints>\n",
        "\n",
        "The most important sections are **Input dataset** and **Expected output**, which are quoted below:\n",
        "\n",
        "## Input dataset\n",
        "For this challenge, when we grade your submission, an input file, `complaints.csv`, will be moved to the top-most `input` directory of your repository. Your code must read that input file, process it and write the results to an output file, `report.csv` that your code must place in the top-most `output` directory of your repository.\n",
        "\n",
        "Below are the contents of an example `complaints.csv` file:\n",
        "```\n",
        "Date received,Product,Sub-product,Issue,Sub-issue,Consumer complaint narrative,Company public response,Company,State,ZIP code,Tags,Consumer consent provided?,Submitted via,Date sent to company,Company response to consumer,Timely response?,Consumer disputed?,Complaint ID\n",
        "2019-09-24,Debt collection,I do not know,Attempts to collect debt not owed,Debt is not yours,\"transworld systems inc. is trying to collect a debt that is not mine, not owed and is inaccurate.\",,TRANSWORLD SYSTEMS INC,FL,335XX,,Consent provided,Web,2019-09-24,Closed with explanation,Yes,N/A,3384392\n",
        "2019-09-19,\"Credit reporting, credit repair services, or other personal consumer reports\",Credit reporting,Incorrect information on your report,Information belongs to someone else,,Company has responded to the consumer and the CFPB and chooses not to provide a public response,Experian Information Solutions Inc.,PA,15206,,Consent not provided,Web,2019-09-20,Closed with non-monetary relief,Yes,N/A,3379500\n",
        "2020-01-06,\"Credit reporting, credit repair services, or other personal consumer reports\",Credit reporting,Incorrect information on your report,Information belongs to someone else,,,Experian Information Solutions Inc.,CA,92532,,N/A,Email,2020-01-06,In progress,Yes,N/A,3486776\n",
        "2019-10-24,\"Credit reporting, credit repair services, or other personal consumer reports\",Credit reporting,Incorrect information on your report,Information belongs to someone else,,Company has responded to the consumer and the CFPB and chooses not to provide a public response,\"TRANSUNION INTERMEDIATE HOLDINGS, INC.\",CA,925XX,,Other,Web,2019-10-24,Closed with explanation,Yes,N/A,3416481\n",
        "2019-11-20,\"Credit reporting, credit repair services, or other personal consumer reports\",Credit reporting,Incorrect information on your report,Account information incorrect,I would like the credit bureau to correct my XXXX XXXX XXXX XXXX balance. My correct balance is XXXX,Company has responded to the consumer and the CFPB and chooses not to provide a public response,\"TRANSUNION INTERMEDIATE HOLDINGS, INC.\",TX,77004,,Consent provided,Web,2019-11-20,Closed with explanation,Yes,N/A,3444592\n",
        "```\n",
        "Each line of the input file, except for the first-line header, represents one complaint. Consult the [Consumer Finance Protection Bureau's technical documentation](https://cfpb.github.io/api/ccdb/fields.html) for a description of each field.  \n",
        "\n",
        "* Notice that complaints were not listed in chronological order\n",
        "* In 2019, there was a complaint against `TRANSWORLD SYSTEMS INC` for `Debt collection`\n",
        "* Also in 2019, `Experian Information Solutions Inc.` received one complaint for `Credit reporting, credit repair services, or other personal consumer reports` while `TRANSUNION INTERMEDIATE HOLDINGS, INC.` received two\n",
        "* In 2020, `Experian Information Solutions Inc.` received a complaint for `Credit reporting, credit repair services, or other personal consumer reports`\n",
        "\n",
        "In summary that means\n",
        "* In 2019, there was one complaint for `Debt collection`, and 100% of it went to one company\n",
        "* Also in 2019, three complaints against two companies were received for `Credit reporting, credit repair services, or other personal consumer reports` and 2/3rd of them (or 67% if we rounded the percentage to the nearest whole number) were against one company (TRANSUNION INTERMEDIATE HOLDINGS, INC.)\n",
        "* In 2020, only one complaint was received for `Credit reporting, credit repair services, or other personal consumer reports`, and so the highest percentage received by one company would be 100%\n",
        "\n",
        "For this challenge, we want for each product and year that complaints were received, the total number of complaints, number of companies receiving a complaint and the highest percentage of complaints directed at a single company.\n",
        "\n",
        "For the purposes of this challenge, all names, including company and product, should be treated as case insensitive. For example, \"Acme\", \"ACME\", and \"acme\" would represent the same company.\n",
        "\n",
        "## Expected output\n",
        "\n",
        "After reading and processing the input file, your code should create an output file, `report.csv`, with as many lines as unique pairs of product and year (of `Date received`) in the input file.\n",
        "\n",
        "Each line in the output file should list the following fields in the following order:\n",
        "* product (name should be written in all lowercase)\n",
        "* year\n",
        "* total number of complaints received for that product and year\n",
        "* total number of companies receiving at least one complaint for that product and year\n",
        "* highest percentage (rounded to the nearest whole number) of total complaints filed against one company for that product and year. Use standard rounding conventions (i.e., Any percentage between 0.5% and 1%, inclusive, should round to 1% and anything less than 0.5% should round to 0%)\n",
        "\n",
        "The lines in the output file should be sorted by product (alphabetically) and year (ascending)\n",
        "\n",
        "Given the above `complaints.csv` input file, we'd expect an output file, `report.csv`, in the following format\n",
        "```\n",
        "\"credit reporting, credit repair services, or other personal consumer reports\",2019,3,2,67\n",
        "\"credit reporting, credit repair services, or other personal consumer reports\",2020,1,1,100\n",
        "debt collection,2019,1,1,100\n",
        "```\n",
        "Notice that because `debt collection` was only listed for 2019 and not 2020, the output file only has a single entry for debt collection. Also, notice that when a product has a comma (`,`) in the name, the name should be enclosed by double quotation marks (`\"`). Finally, notice that percentages are listed as numbers and do not have `%` in them.\n",
        "\n",
        "# Objectives\n",
        "\n",
        "In this homework, we will tackle the above problem in two steps (2 tasks):\n",
        "\n",
        "1. In Task 1, we work on a solution with PySpark on Google Colab using a sample of the data. The data is available on Google Drive and is to be downloaded by the `gdown` command in Task 1.\n",
        "\n",
        "2. In Task 2, we create a standalone Python script that work on the full dataset using GCP DataProc. The full dataset is downloaded from [here](https://www.consumerfinance.gov/data-research/consumer-complaints/#download-the-data). The data is available on the class bucket as: `gs://bdma/data/complaints.csv`\n",
        "\n"
      ],
      "metadata": {
        "id": "gbF71GHptuwV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Setup"
      ],
      "metadata": {
        "id": "VBWF5LNefozN"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjzjcPWYnHLr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02e5f025-abd0-407e-ef2f-fed3d343229c"
      },
      "source": [
        "%%shell\n",
        "gdown --quiet 1-IeoZDwT5wQzBUpsaS5B6vTaP-2ZBkam\n",
        "pip --quiet install pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHKq10WXnZl7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "d6007edc-1de7-468d-c77e-fcf2b3de7183"
      },
      "source": [
        "COMPLAINTS_FN = 'complaints_sample.csv'\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql import types as T\n",
        "sc = pyspark.SparkContext.getOrCreate()\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "spark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f8e401b3670>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://2a58996adf4e:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9Ykp1Qqnu5f"
      },
      "source": [
        "## Task 1\n",
        "\n",
        "Use PySpark to derive the expected output. Your computation must be done entirely on Spark's transformation. The output MUST be in the CSV form, i.e. each output line is a complete comma separated string that can be fed into a CSV reader. It is okay if your output are divided into multiple parts (due to the nature of distributed computing of Spark)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "len(list(csv.reader(open(COMPLAINTS_FN, 'r'))))-1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grm6dQ6F2nQA",
        "outputId": "27c6b99e-85c7-40ee-9f48-879ec69e4bf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6623"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08oVX9j82qek",
        "outputId": "2256d0ed-997e-4329-9f53-bdc48a551cd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 3.8M\n",
            "-rw-r--r-- 1 root root 3.8M Apr 15 04:48 complaints_sample.csv\n",
            "drwxr-xr-x 1 root root 4.0K Apr 13 13:30 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wc -l {COMPLAINTS_FN}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzX29t0T2qiV",
        "outputId": "0dc6c9d9-49dc-4f28-d8a3-93f264075a4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9965 complaints_sample.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 7 {COMPLAINTS_FN}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQUrKztW2ql8",
        "outputId": "f5d7a5bf-ee0f-43f7-eecd-fde8525db721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Date received,Product,Sub-product,Issue,Sub-issue,Consumer complaint narrative,Company public response,Company,State,ZIP code,Tags,Consumer consent provided?,Submitted via,Date sent to company,Company response to consumer,Timely response?,Consumer disputed?,Complaint ID\r\n",
            "2015-12-31,Bank account or service,Checking account,\"Making/receiving payments, sending money\",,,,FIRSTBANK PUERTO RICO,PR,00902,Older American,N/A,Referral,2016-02-04,Closed with explanation,Yes,No,1723943\r\n",
            "2016-03-15,Bank account or service,Other bank product/service,Problems caused by my funds being low,,,,FIRSTBANK PUERTO RICO,PR,00926,,Consent not provided,Web,2016-03-15,Closed with explanation,Yes,No,1833740\r\n",
            "2016-10-24,Bank account or service,Checking account,\"Account opening, closing, or management\",,\"In the month of XX/XX/2015, my email address ( XXXX ) was hacked and used to send messages to people associated with my business. At that time, transactions for the purchase and sales of products were made. The hacker forged the identities of our customers and suppliers, creating email addresses similar to those recorded in our email account, which they then used to communicate with our customers, our suppliers, and us. \n",
            "\n",
            "The hackers fraudulently and inexplicably opened XXXX ( XXXX ) accounts with WELLS FARGO BANK in XXXX XXXX, California.\",Company has responded to the consumer and the CFPB and chooses not to provide a public response,WELLS FARGO & COMPANY,PR,00969,,Consent provided,Web,2016-12-28,Closed with non-monetary relief,Yes,No,2175792\r\n",
            "2017-09-08,Checking or savings account,Checking account,Managing an account,Deposits and withdrawals,,,Comerica,TX,77551,,N/A,Referral,2017-11-07,Closed with explanation,Yes,N/A,2668920\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.load(COMPLAINTS_FN, format='csv', header=True)\n",
        "print(df.count())\n",
        "df.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DY0ySECK2vkZ",
        "outputId": "fa99c574-e848-46b6-b6df-12ece00abd1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8595\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+----------------------------+-----------------------+--------------------+-----+----------+--------------------+--------------------------+-------------+--------------------+----------------------------+----------------+------------------+------------+\n",
            "|       Date received|             Product|         Sub-product|               Issue|           Sub-issue|Consumer complaint narrative|Company public response|             Company|State|  ZIP code|                Tags|Consumer consent provided?|Submitted via|Date sent to company|Company response to consumer|Timely response?|Consumer disputed?|Complaint ID|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+----------------------------+-----------------------+--------------------+-----+----------+--------------------+--------------------------+-------------+--------------------+----------------------------+----------------+------------------+------------+\n",
            "|          2015-12-31|Bank account or s...|    Checking account|Making/receiving ...|                null|                        null|                   null|FIRSTBANK PUERTO ...|   PR|     00902|      Older American|                       N/A|     Referral|          2016-02-04|        Closed with expla...|             Yes|                No|     1723943|\n",
            "|          2016-03-15|Bank account or s...|Other bank produc...|Problems caused b...|                null|                        null|                   null|FIRSTBANK PUERTO ...|   PR|     00926|                null|      Consent not provided|          Web|          2016-03-15|        Closed with expla...|             Yes|                No|     1833740|\n",
            "|          2016-10-24|Bank account or s...|    Checking account|Account opening, ...|                null|        In the month of X...|                   null|                null| null|      null|                null|                      null|         null|                null|                        null|            null|              null|        null|\n",
            "|The hackers fraud...|        California.\"|Company has respo...|WELLS FARGO & COM...|                  PR|                       00969|                   null|    Consent provided|  Web|2016-12-28|Closed with non-m...|                       Yes|           No|             2175792|                        null|            null|              null|        null|\n",
            "|          2017-09-08|Checking or savin...|    Checking account| Managing an account|Deposits and with...|                        null|                   null|            Comerica|   TX|     77551|                null|                       N/A|     Referral|          2017-11-07|        Closed with expla...|             Yes|               N/A|     2668920|\n",
            "|          2018-09-19|Checking or savin...|    Checking account|Problem with a le...|Money was taken f...|                        null|   Company has respo...|WELLS FARGO & COM...|   FL|     33326|                null|      Consent not provided|          Web|          2018-09-19|        Closed with expla...|             Yes|               N/A|     3023007|\n",
            "|          2018-12-04|Checking or savin...|    Checking account| Managing an account|Deposits and with...|                        null|   Company has respo...|BANK OF AMERICA, ...|   MI|     48146|                null|                       N/A|     Referral|          2018-12-11|        Closed with expla...|             Yes|               N/A|     3093436|\n",
            "|          2018-12-05|Checking or savin...|Other banking pro...| Managing an account|Deposits and with...|        On the XX/XX/2018...|                   null|                null| null|      null|                null|                      null|         null|                null|                        null|            null|              null|        null|\n",
            "|Despite contactin...| the bank refused...| the bank finally...| could not be wai...| which led to a {...|         and didn't tell ...|                   null|                null| null|      null|                null|                      null|         null|                null|                        null|            null|              null|        null|\n",
            "|I was forced to l...|                null|                null|                null|                null|                        null|                   null|                null| null|      null|                null|                      null|         null|                null|                        null|            null|              null|        null|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+----------------------------+-----------------------+--------------------+-----+----------+--------------------+--------------------------+-------------+--------------------+----------------------------+----------------+------------------+------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfA = spark.read.option('escape', '\"').option('multiLine', True).csv(COMPLAINTS_FN, header=True, inferSchema=True) \\\n",
        "     .select('Date received','Product','Company')\n",
        "print(dfA.count())\n",
        "dfA.show(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBQaxU9L2vna",
        "outputId": "e6e84dfa-173e-4aae-f6a2-71175001cb8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6623\n",
            "+-------------+--------------------+--------------------+\n",
            "|Date received|             Product|             Company|\n",
            "+-------------+--------------------+--------------------+\n",
            "|   2015-12-31|Bank account or s...|FIRSTBANK PUERTO ...|\n",
            "|   2016-03-15|Bank account or s...|FIRSTBANK PUERTO ...|\n",
            "|   2016-10-24|Bank account or s...|WELLS FARGO & COM...|\n",
            "|   2017-09-08|Checking or savin...|            Comerica|\n",
            "|   2018-09-19|Checking or savin...|WELLS FARGO & COM...|\n",
            "|   2018-12-04|Checking or savin...|BANK OF AMERICA, ...|\n",
            "|   2018-12-05|Checking or savin...|HSBC NORTH AMERIC...|\n",
            "|   2018-12-06|Checking or savin...|JPMORGAN CHASE & CO.|\n",
            "|   2018-12-10|Checking or savin...|NAVY FEDERAL CRED...|\n",
            "|   2018-12-10|Checking or savin...|JPMORGAN CHASE & CO.|\n",
            "|   2018-12-13|Checking or savin...|       PNC Bank N.A.|\n",
            "|   2018-12-13|Checking or savin...|REGIONS FINANCIAL...|\n",
            "|   2018-12-16|Checking or savin...|UNITED SERVICES A...|\n",
            "|   2018-12-17|Checking or savin...|BBVA FINANCIAL CO...|\n",
            "|   2018-12-18|Checking or savin...|REGIONS FINANCIAL...|\n",
            "|   2018-12-18|Checking or savin...|            Comerica|\n",
            "|   2018-12-18|Checking or savin...|JPMORGAN CHASE & CO.|\n",
            "|   2018-12-19|Checking or savin...|JPMORGAN CHASE & CO.|\n",
            "|   2018-12-19|Checking or savin...|BBVA FINANCIAL CO...|\n",
            "|   2018-12-22|Checking or savin...|NAVY FEDERAL CRED...|\n",
            "+-------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import year, lower\n",
        "dfB = dfA.withColumn('Product', lower('Product')) \\\n",
        "         .withColumn('Company', lower('Company'))\n",
        "\n",
        "print(dfB.count())\n",
        "dfB.show(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJMXd0gm2vqe",
        "outputId": "1b0536e3-934b-4d68-aee3-94ced70c1f7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6623\n",
            "+-------------+--------------------+--------------------+\n",
            "|Date received|             Product|             Company|\n",
            "+-------------+--------------------+--------------------+\n",
            "|   2015-12-31|bank account or s...|firstbank puerto ...|\n",
            "|   2016-03-15|bank account or s...|firstbank puerto ...|\n",
            "|   2016-10-24|bank account or s...|wells fargo & com...|\n",
            "|   2017-09-08|checking or savin...|            comerica|\n",
            "|   2018-09-19|checking or savin...|wells fargo & com...|\n",
            "|   2018-12-04|checking or savin...|bank of america, ...|\n",
            "|   2018-12-05|checking or savin...|hsbc north americ...|\n",
            "|   2018-12-06|checking or savin...|jpmorgan chase & co.|\n",
            "|   2018-12-10|checking or savin...|navy federal cred...|\n",
            "|   2018-12-10|checking or savin...|jpmorgan chase & co.|\n",
            "|   2018-12-13|checking or savin...|       pnc bank n.a.|\n",
            "|   2018-12-13|checking or savin...|regions financial...|\n",
            "|   2018-12-16|checking or savin...|united services a...|\n",
            "|   2018-12-17|checking or savin...|bbva financial co...|\n",
            "|   2018-12-18|checking or savin...|regions financial...|\n",
            "|   2018-12-18|checking or savin...|            comerica|\n",
            "|   2018-12-18|checking or savin...|jpmorgan chase & co.|\n",
            "|   2018-12-19|checking or savin...|jpmorgan chase & co.|\n",
            "|   2018-12-19|checking or savin...|bbva financial co...|\n",
            "|   2018-12-22|checking or savin...|navy federal cred...|\n",
            "+-------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the required values\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "df2 = dfB.groupBy('Product', year('Date received').alias('Year'), 'Company') \\\n",
        "       .agg(F.count('*').alias('Complaints')) \\\n",
        "       .groupBy('Product', 'Year') \\\n",
        "       .agg(F.sum('Complaints').alias('Total Complaints'),\n",
        "            F.countDistinct('Company').alias('Total Companies'),\n",
        "            F.max('Complaints').alias('Max Complaints'),\n",
        "            F.sum('Complaints').alias('Complaints')) \\\n",
        "       .withColumn('Max Percentage', F.round(F.col('Max Complaints')/F.col('Complaints') * 100).cast(T.IntegerType())) \\\n",
        "       .select('Product', 'Year', 'Total Complaints', 'Total Companies', 'Max Percentage')\n",
        "\n",
        "print(df2.count())\n",
        "df2.show(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F019kT2c2vu_",
        "outputId": "e46d7876-0d86-4a91-b407-de0352a0578e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46\n",
            "+--------------------+----+----------------+---------------+--------------+\n",
            "|             Product|Year|Total Complaints|Total Companies|Max Percentage|\n",
            "+--------------------+----+----------------+---------------+--------------+\n",
            "|credit reporting,...|2019|            3114|            203|            50|\n",
            "|         credit card|2016|               4|              4|            25|\n",
            "|checking or savin...|2020|               3|              3|            33|\n",
            "|money transfer, v...|2019|              87|             33|            33|\n",
            "|            mortgage|2018|              39|             27|            10|\n",
            "|credit card or pr...|2019|             437|             42|            15|\n",
            "|       consumer loan|2015|               1|              1|           100|\n",
            "|     debt collection|2017|              13|             11|            15|\n",
            "|            mortgage|2019|             415|             98|            10|\n",
            "|        student loan|2019|             157|             37|            37|\n",
            "|payday loan, titl...|2020|               1|              1|           100|\n",
            "|     debt collection|2015|               4|              3|            50|\n",
            "|checking or savin...|2019|             461|             72|            13|\n",
            "|checking or savin...|2017|               1|              1|           100|\n",
            "|payday loan, titl...|2018|               7|              2|            86|\n",
            "|vehicle loan or l...|2018|              10|              9|            20|\n",
            "|            mortgage|2020|               6|              6|            17|\n",
            "|checking or savin...|2018|              20|             10|            25|\n",
            "|bank account or s...|2016|               2|              2|            50|\n",
            "|            mortgage|2017|               3|              3|            33|\n",
            "+--------------------+----+----------------+---------------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sort the output by product and year\n",
        "df3 = df2.orderBy('Product', 'Year')\n",
        "print(df3.count())\n",
        "df3.show(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TaHUkih27Og",
        "outputId": "0670dc40-683b-4a64-ba34-0609c38049b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46\n",
            "+--------------------+----+----------------+---------------+--------------+\n",
            "|             Product|Year|Total Complaints|Total Companies|Max Percentage|\n",
            "+--------------------+----+----------------+---------------+--------------+\n",
            "|bank account or s...|2015|               1|              1|           100|\n",
            "|bank account or s...|2016|               2|              2|            50|\n",
            "|checking or savin...|2017|               1|              1|           100|\n",
            "|checking or savin...|2018|              20|             10|            25|\n",
            "|checking or savin...|2019|             461|             72|            13|\n",
            "|checking or savin...|2020|               3|              3|            33|\n",
            "|       consumer loan|2015|               1|              1|           100|\n",
            "|       consumer loan|2016|               1|              1|           100|\n",
            "|       consumer loan|2017|               1|              1|           100|\n",
            "|         credit card|2016|               4|              4|            25|\n",
            "|         credit card|2017|               1|              1|           100|\n",
            "|credit card or pr...|2017|               1|              1|           100|\n",
            "|credit card or pr...|2018|              27|             12|            33|\n",
            "|credit card or pr...|2019|             437|             42|            15|\n",
            "|credit card or pr...|2020|              13|             10|            23|\n",
            "|credit reporting,...|2017|               7|              5|            29|\n",
            "|credit reporting,...|2018|             238|             22|            56|\n",
            "|credit reporting,...|2019|            3114|            203|            50|\n",
            "|credit reporting,...|2020|             144|             10|            51|\n",
            "|     debt collection|2015|               4|              3|            50|\n",
            "+--------------------+----+----------------+---------------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KMokGLsc27VG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# outputTask1 is an output RDD, you can use DataFrame as well but each line\n",
        "# still needs to be a string\n",
        "outputTask1.take(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1r07D6MEMOq",
        "outputId": "55bc3423-82c7-46c3-b60a-70fcdaaae880"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bank account or service,2015,1,1,100',\n",
              " 'bank account or service,2016,2,2,50',\n",
              " 'checking or savings account,2017,1,1,100',\n",
              " 'checking or savings account,2018,20,10,25',\n",
              " 'checking or savings account,2019,461,72,13',\n",
              " 'checking or savings account,2020,3,3,33',\n",
              " 'consumer loan,2015,1,1,100',\n",
              " 'consumer loan,2016,1,1,100',\n",
              " 'consumer loan,2017,1,1,100',\n",
              " 'credit card,2016,4,4,25',\n",
              " 'credit card,2017,1,1,100',\n",
              " 'credit card or prepaid card,2017,1,1,100',\n",
              " 'credit card or prepaid card,2018,27,12,33',\n",
              " 'credit card or prepaid card,2019,437,42,15',\n",
              " 'credit card or prepaid card,2020,13,10,23',\n",
              " 'credit reporting, credit repair services, or other personal consumer reports,2017,7,5,29',\n",
              " 'credit reporting, credit repair services, or other personal consumer reports,2018,238,22,56',\n",
              " 'credit reporting, credit repair services, or other personal consumer reports,2019,3114,203,50',\n",
              " 'credit reporting, credit repair services, or other personal consumer reports,2020,144,10,51',\n",
              " 'debt collection,2015,4,3,50']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2\n",
        "\n",
        "For this task, please convert what you have in Task 1 to a standalone file that can be run on any DataProc cluster. The input and output locations must be taken from the command line, e.g. using my cluster named `bdma`:\n",
        "\n",
        "```shell\n",
        "gcloud dataproc jobs submit pyspark --cluster bdma BDM_HW3_EMPLID_LastName.py gs://bdma/data/complaints.csv gs://bdma/shared/2023_spring/HW3/EMPLID_LastName\n",
        "```\n",
        "\n",
        "As part of the test, you must be able to run your code and output to the class shared folder, i.e.: `gs://bdma/shared/2023_spring/HW3/EMPLID_LastName`, **replacing `EMPLID` and `LastName` with your actual EMPL ID and Last Name**.\n",
        "\n",
        "Note that, if you run your code multiple times, make sure to only run your working version when output to the shared folder, or you must remove the existing output to run your code again.\n",
        "\n",
        "### For PhD students\n",
        "\n",
        "Your solution must take into account multiple line records without coalescing into a single partition and count them all in the output. We should have *3,458,906* records in the full dataset."
      ],
      "metadata": {
        "id": "oNXJMMLEEcHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-dataproc"
      ],
      "metadata": {
        "id": "VJecoKVsqJcJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "0c107e50-b2f9-4cfa-9534-ef6cacabdb14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting google-cloud-dataproc\n",
            "  Downloading google_cloud_dataproc-5.4.1-py2.py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.5/307.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting grpc-google-iam-v1<1.0.0dev,>=0.12.4\n",
            "  Downloading grpc_google_iam_v1-0.12.6-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.9/dist-packages (from google-cloud-dataproc) (1.22.2)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0 in /usr/local/lib/python3.9/dist-packages (from google-cloud-dataproc) (2.11.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.9/dist-packages (from google-cloud-dataproc) (3.20.3)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=2.14.1 in /usr/local/lib/python3.9/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-dataproc) (2.17.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.9/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-dataproc) (1.59.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.9/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-dataproc) (2.27.1)\n",
            "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.9/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-dataproc) (1.48.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.9/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-dataproc) (1.53.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-dataproc) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-dataproc) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-dataproc) (5.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-dataproc) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-dataproc) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-dataproc) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-dataproc) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-dataproc) (2.0.12)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-dataproc) (0.4.8)\n",
            "Installing collected packages: grpc-google-iam-v1, google-cloud-dataproc\n",
            "Successfully installed google-cloud-dataproc-5.4.1 grpc-google-iam-v1-0.12.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud auth login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0s2ez0gx8vhp",
        "outputId": "b58a06f7-277d-45d7-a867-027f26115fcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go to the following link in your browser:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=32555940559.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=24obxA9Oen40eZa7eeWAq119K4dkH9&prompt=consent&access_type=offline&code_challenge=8v4Ine_Yr0uOwdi4knyFF6emS6ZzqVqMa59i-budVmQ&code_challenge_method=S256\n",
            "\n",
            "Enter authorization code: 4/0AVHEtk5Otbod8kUgpdZZKDw-1mZ853w9XPbKZCCkNmsnhBbUEKyS9a3dvqKHz4ex1JmE1Q\n",
            "\n",
            "You are now logged in as [sumaiyauddin1995@gmail.com].\n",
            "Your current project is [None].  You can change this setting by running:\n",
            "  $ gcloud config set project PROJECT_ID\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud projects list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEKMD5mV8vnq",
        "outputId": "00b9b33f-b9f1-4b6f-b312-1a51921eb247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PROJECT_ID             NAME              PROJECT_NUMBER\n",
            "big-data-380022        big data          901723776519\n",
            "rich-suprstate-380020  My First Project  72957410723\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud config set project big-data-380022\n",
        "!gcloud config set compute/region us-west1\n",
        "!gcloud config set compute/zone us-west1-a\n",
        "!gcloud config set dataproc/region us-west1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udt64toH8vtE",
        "outputId": "6d53b99a-628f-4d63-a22a-ab807372cca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n",
            "Updated property [compute/region].\n",
            "Updated property [compute/zone].\n",
            "Updated property [dataproc/region].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud dataproc clusters create bdma --enable-component-gateway --region us-west1 --zone us-west1-a --master-machine-type n1-standard-4 --master-boot-disk-size 500 --num-workers 2 --worker-machine-type n1-standard-4 --worker-boot-disk-size 500 --image-version 2.0-debian10 --project big-data-380022"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1KTf7hG8vwm",
        "outputId": "fd32ba07-99b4-4baa-baf4-577cc81e2216"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;31mERROR:\u001b[0m (gcloud.dataproc.clusters.create) ALREADY_EXISTS: Already exists: Failed to create cluster: Cluster projects/big-data-380022/regions/us-west1/clusters/bdma\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud dataproc clusters list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mV_cQCLA8vzv",
        "outputId": "453e1c77-490a-473f-947d-e8c8363fde31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME  PLATFORM  WORKER_COUNT  PREEMPTIBLE_WORKER_COUNT  STATUS   ZONE        SCHEDULED_DELETE\n",
            "bdma  GCE       2                                       RUNNING  us-west1-a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud dataproc clusters describe bdma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eMBxG0U8v2j",
        "outputId": "8210f678-338c-4320-c4c0-dfbbdfc1005d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clusterName: bdma\n",
            "clusterUuid: a199b803-8e6d-40e6-8f25-be0de8a8d5db\n",
            "config:\n",
            "  configBucket: dataproc-staging-us-west1-901723776519-ddnkwogk\n",
            "  endpointConfig:\n",
            "    enableHttpPortAccess: true\n",
            "    httpPorts:\n",
            "      HDFS NameNode: https://kf5ele4aq5cqvdvfjmutptdjpu-dot-us-west1.dataproc.googleusercontent.com/hdfs/dfshealth.html\n",
            "      HiveServer2 (bdma-m): https://kf5ele4aq5cqvdvfjmutptdjpu-dot-us-west1.dataproc.googleusercontent.com/hiveserver2ui/bdma-m?host=bdma-m\n",
            "      MapReduce Job History: https://kf5ele4aq5cqvdvfjmutptdjpu-dot-us-west1.dataproc.googleusercontent.com/jobhistory/\n",
            "      Spark History Server: https://kf5ele4aq5cqvdvfjmutptdjpu-dot-us-west1.dataproc.googleusercontent.com/sparkhistory/\n",
            "      Tez: https://kf5ele4aq5cqvdvfjmutptdjpu-dot-us-west1.dataproc.googleusercontent.com/apphistory/tez-ui/\n",
            "      YARN Application Timeline: https://kf5ele4aq5cqvdvfjmutptdjpu-dot-us-west1.dataproc.googleusercontent.com/apphistory/\n",
            "      YARN ResourceManager: https://kf5ele4aq5cqvdvfjmutptdjpu-dot-us-west1.dataproc.googleusercontent.com/yarn/\n",
            "  gceClusterConfig:\n",
            "    internalIpOnly: false\n",
            "    networkUri: https://www.googleapis.com/compute/v1/projects/big-data-380022/global/networks/default\n",
            "    serviceAccountScopes:\n",
            "    - https://www.googleapis.com/auth/bigquery\n",
            "    - https://www.googleapis.com/auth/bigtable.admin.table\n",
            "    - https://www.googleapis.com/auth/bigtable.data\n",
            "    - https://www.googleapis.com/auth/cloud.useraccounts.readonly\n",
            "    - https://www.googleapis.com/auth/devstorage.full_control\n",
            "    - https://www.googleapis.com/auth/devstorage.read_write\n",
            "    - https://www.googleapis.com/auth/logging.write\n",
            "    zoneUri: https://www.googleapis.com/compute/v1/projects/big-data-380022/zones/us-west1-a\n",
            "  masterConfig:\n",
            "    diskConfig:\n",
            "      bootDiskSizeGb: 500\n",
            "      bootDiskType: pd-standard\n",
            "    imageUri: https://www.googleapis.com/compute/v1/projects/cloud-dataproc/global/images/dataproc-2-0-deb10-20230327-165100-rc01\n",
            "    instanceNames:\n",
            "    - bdma-m\n",
            "    machineTypeUri: https://www.googleapis.com/compute/v1/projects/big-data-380022/zones/us-west1-a/machineTypes/n1-standard-4\n",
            "    minCpuPlatform: AUTOMATIC\n",
            "    numInstances: 1\n",
            "    preemptibility: NON_PREEMPTIBLE\n",
            "  softwareConfig:\n",
            "    imageVersion: 2.0.61-debian10\n",
            "    properties:\n",
            "      capacity-scheduler:yarn.scheduler.capacity.root.default.ordering-policy: fair\n",
            "      core:fs.gs.block.size: '134217728'\n",
            "      core:fs.gs.metadata.cache.enable: 'false'\n",
            "      core:hadoop.ssl.enabled.protocols: TLSv1,TLSv1.1,TLSv1.2\n",
            "      distcp:mapreduce.map.java.opts: -Xmx768m\n",
            "      distcp:mapreduce.map.memory.mb: '1024'\n",
            "      distcp:mapreduce.reduce.java.opts: -Xmx768m\n",
            "      distcp:mapreduce.reduce.memory.mb: '1024'\n",
            "      hadoop-env:HADOOP_DATANODE_OPTS: -Xmx512m\n",
            "      hdfs:dfs.datanode.address: 0.0.0.0:9866\n",
            "      hdfs:dfs.datanode.http.address: 0.0.0.0:9864\n",
            "      hdfs:dfs.datanode.https.address: 0.0.0.0:9865\n",
            "      hdfs:dfs.datanode.ipc.address: 0.0.0.0:9867\n",
            "      hdfs:dfs.namenode.handler.count: '20'\n",
            "      hdfs:dfs.namenode.http-address: 0.0.0.0:9870\n",
            "      hdfs:dfs.namenode.https-address: 0.0.0.0:9871\n",
            "      hdfs:dfs.namenode.lifeline.rpc-address: bdma-m:8050\n",
            "      hdfs:dfs.namenode.secondary.http-address: 0.0.0.0:9868\n",
            "      hdfs:dfs.namenode.secondary.https-address: 0.0.0.0:9869\n",
            "      hdfs:dfs.namenode.service.handler.count: '10'\n",
            "      hdfs:dfs.namenode.servicerpc-address: bdma-m:8051\n",
            "      hive:hive.fetch.task.conversion: none\n",
            "      mapred-env:HADOOP_JOB_HISTORYSERVER_HEAPSIZE: '3840'\n",
            "      mapred:mapreduce.job.maps: '21'\n",
            "      mapred:mapreduce.job.reduce.slowstart.completedmaps: '0.95'\n",
            "      mapred:mapreduce.job.reduces: '7'\n",
            "      mapred:mapreduce.jobhistory.recovery.store.class: org.apache.hadoop.mapreduce.v2.hs.HistoryServerLeveldbStateStoreService\n",
            "      mapred:mapreduce.map.cpu.vcores: '1'\n",
            "      mapred:mapreduce.map.java.opts: -Xmx2524m\n",
            "      mapred:mapreduce.map.memory.mb: '3156'\n",
            "      mapred:mapreduce.reduce.cpu.vcores: '1'\n",
            "      mapred:mapreduce.reduce.java.opts: -Xmx2524m\n",
            "      mapred:mapreduce.reduce.memory.mb: '3156'\n",
            "      mapred:mapreduce.task.io.sort.mb: '256'\n",
            "      mapred:yarn.app.mapreduce.am.command-opts: -Xmx2524m\n",
            "      mapred:yarn.app.mapreduce.am.resource.cpu-vcores: '1'\n",
            "      mapred:yarn.app.mapreduce.am.resource.mb: '3156'\n",
            "      spark-env:SPARK_DAEMON_MEMORY: 3840m\n",
            "      spark:spark.driver.maxResultSize: 1920m\n",
            "      spark:spark.driver.memory: 3840m\n",
            "      spark:spark.executor.cores: '2'\n",
            "      spark:spark.executor.instances: '2'\n",
            "      spark:spark.executor.memory: 5739m\n",
            "      spark:spark.executorEnv.OPENBLAS_NUM_THREADS: '1'\n",
            "      spark:spark.extraListeners: com.google.cloud.spark.performance.DataprocMetricsListener\n",
            "      spark:spark.scheduler.mode: FAIR\n",
            "      spark:spark.sql.cbo.enabled: 'true'\n",
            "      spark:spark.ui.port: '0'\n",
            "      spark:spark.yarn.am.memory: 640m\n",
            "      yarn-env:YARN_NODEMANAGER_HEAPSIZE: '1536'\n",
            "      yarn-env:YARN_RESOURCEMANAGER_HEAPSIZE: '3840'\n",
            "      yarn-env:YARN_TIMELINESERVER_HEAPSIZE: '3840'\n",
            "      yarn:yarn.nodemanager.address: 0.0.0.0:8026\n",
            "      yarn:yarn.nodemanager.resource.cpu-vcores: '4'\n",
            "      yarn:yarn.nodemanager.resource.memory-mb: '12624'\n",
            "      yarn:yarn.resourcemanager.nodemanager-graceful-decommission-timeout-secs: '86400'\n",
            "      yarn:yarn.scheduler.maximum-allocation-mb: '12624'\n",
            "      yarn:yarn.scheduler.minimum-allocation-mb: '1'\n",
            "  tempBucket: dataproc-temp-us-west1-901723776519-0bznrotf\n",
            "  workerConfig:\n",
            "    diskConfig:\n",
            "      bootDiskSizeGb: 500\n",
            "      bootDiskType: pd-standard\n",
            "    imageUri: https://www.googleapis.com/compute/v1/projects/cloud-dataproc/global/images/dataproc-2-0-deb10-20230327-165100-rc01\n",
            "    instanceNames:\n",
            "    - bdma-w-0\n",
            "    - bdma-w-1\n",
            "    machineTypeUri: https://www.googleapis.com/compute/v1/projects/big-data-380022/zones/us-west1-a/machineTypes/n1-standard-4\n",
            "    minCpuPlatform: AUTOMATIC\n",
            "    numInstances: 2\n",
            "    preemptibility: NON_PREEMPTIBLE\n",
            "labels:\n",
            "  goog-dataproc-cluster-name: bdma\n",
            "  goog-dataproc-cluster-uuid: a199b803-8e6d-40e6-8f25-be0de8a8d5db\n",
            "  goog-dataproc-location: us-west1\n",
            "metrics:\n",
            "  hdfsMetrics:\n",
            "    dfs-blocks-corrupt: '0'\n",
            "    dfs-blocks-default-replication-factor: '2'\n",
            "    dfs-blocks-missing: '0'\n",
            "    dfs-blocks-missing-repl-one: '0'\n",
            "    dfs-blocks-pending-deletion: '0'\n",
            "    dfs-blocks-under-replication: '0'\n",
            "    dfs-capacity-present: '988856107008'\n",
            "    dfs-capacity-remaining: '988856057856'\n",
            "    dfs-capacity-total: '1056347095040'\n",
            "    dfs-capacity-used: '49152'\n",
            "    dfs-nodes-decommissioned: '0'\n",
            "    dfs-nodes-decommissioning: '0'\n",
            "    dfs-nodes-running: '2'\n",
            "  yarnMetrics:\n",
            "    yarn-apps-completed: '0'\n",
            "    yarn-apps-failed: '0'\n",
            "    yarn-apps-killed: '0'\n",
            "    yarn-apps-pending: '0'\n",
            "    yarn-apps-running: '0'\n",
            "    yarn-apps-submitted: '0'\n",
            "    yarn-containers-allocated: '0'\n",
            "    yarn-containers-pending: '0'\n",
            "    yarn-containers-reserved: '0'\n",
            "    yarn-memory-mb-allocated: '0'\n",
            "    yarn-memory-mb-available: '25248'\n",
            "    yarn-memory-mb-pending: '0'\n",
            "    yarn-memory-mb-reserved: '0'\n",
            "    yarn-memory-mb-total: '25248'\n",
            "    yarn-nodes-active: '2'\n",
            "    yarn-nodes-decommissioned: '0'\n",
            "    yarn-nodes-decommissioning: '0'\n",
            "    yarn-nodes-lost: '0'\n",
            "    yarn-nodes-new: '0'\n",
            "    yarn-nodes-rebooted: '0'\n",
            "    yarn-nodes-shutdown: '0'\n",
            "    yarn-nodes-unhealthy: '0'\n",
            "    yarn-vcores-allocated: '0'\n",
            "    yarn-vcores-available: '8'\n",
            "    yarn-vcores-pending: '0'\n",
            "    yarn-vcores-reserved: '0'\n",
            "    yarn-vcores-total: '8'\n",
            "projectId: big-data-380022\n",
            "status:\n",
            "  state: RUNNING\n",
            "  stateStartTime: '2023-04-15T05:57:33.466858Z'\n",
            "statusHistory:\n",
            "- state: CREATING\n",
            "  stateStartTime: '2023-04-15T05:55:36.000845Z'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile BDM_HW3_24373710_Uddin.py\n",
        "#!/usr/bin/python\n",
        "\n",
        "import pyspark\n",
        "import sys\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql import types as T\n",
        "from pyspark.sql.functions import lower, year\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # read input and output paths from command line arguments\n",
        "    input_path = sys.argv[1]\n",
        "    output_path = sys.argv[2]\n",
        "\n",
        "    sc = pyspark.SparkContext.getOrCreate()\n",
        "    spark = SparkSession.builder.config(\"spark.sql.shuffle.partitions\", \"200\").getOrCreate()\n",
        "\n",
        "    # define the schema for the CSV file\n",
        "    schema = T.StructType([\n",
        "        T.StructField('Date received', T.DateType()),\n",
        "        T.StructField('Product', T.StringType()),\n",
        "        T.StructField('Company', T.StringType())\n",
        "    ])\n",
        "\n",
        "    # read the csv file into a DataFrame\n",
        "    dfA = spark.read.option('escape', '\"').option('multiLine', True).csv(input_path, header=True, inferSchema=True) \\\n",
        "     .select('Date received','Product','Company')\n",
        "\n",
        "    # lowercase product and company columns\n",
        "    dfB = dfA.withColumn('Product', lower('Product')) \\\n",
        "         .withColumn('Company', lower('Company'))\n",
        "\n",
        "    # calculate the required values\n",
        "    df2 = dfB.groupBy('Product', year('Date received').alias('Year'), 'Company') \\\n",
        "          .agg(F.count('*').alias('Complaints')) \\\n",
        "          .groupBy('Product', 'Year') \\\n",
        "          .agg(F.sum('Complaints').alias('Total Complaints'),\n",
        "                F.countDistinct('Company').alias('Total Companies'),\n",
        "                F.max('Complaints').alias('Max Complaints'),\n",
        "                F.sum('Complaints').alias('Complaints')) \\\n",
        "          .withColumn('Max Percentage', F.round(F.col('Max Complaints')/F.col('Complaints') * 100).cast(T.IntegerType())) \\\n",
        "          .select('Product', 'Year', 'Total Complaints', 'Total Companies', 'Max Percentage')\n",
        "\n",
        "    # sort and save results to output folder\n",
        "    df3 = df2.orderBy('Product', 'Year')\n",
        "\n",
        "    # write output to file\n",
        "    df3.write.format('csv').option('header', True).mode('overwrite').save(output_path)\n",
        "\n",
        "    # stop SparkSession\n",
        "    spark.stop()\n",
        "\n",
        "    print('Completed')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlSddqU48v8E",
        "outputId": "20fae444-37fd-4375-b5ab-41ae4b3021d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing BDM_HW3_24373710_Uddin.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !gcloud dataproc jobs submit pyspark --cluster bdma BDM_HW3_24373710_Uddin.py gs://bdma/data/complaints.csv gs://bdma/shared/2023_spring/HW3/24373710_Uddin"
      ],
      "metadata": {
        "id": "ZOhTsQK18v-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud dataproc jobs submit pyspark --cluster bdma BDM_HW3_24373710_Uddin.py -- gs://bdma/data/complaints.csv gs://bdma/shared/2023_spring/HW3/24373710_Uddin"
      ],
      "metadata": {
        "id": "dmp2TQXn8wBw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8d0e973-40bd-4357-9a34-9d10ccefffc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job [fbdf9c7d90ec4e5080259b35e88f4c2c] submitted.\n",
            "Waiting for job output...\n",
            "23/04/15 06:01:24 INFO org.apache.spark.SparkEnv: Registering MapOutputTracker\n",
            "23/04/15 06:01:24 INFO org.apache.spark.SparkEnv: Registering BlockManagerMaster\n",
            "23/04/15 06:01:24 INFO org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n",
            "23/04/15 06:01:24 INFO org.apache.spark.SparkEnv: Registering OutputCommitCoordinator\n",
            "23/04/15 06:01:25 INFO org.sparkproject.jetty.util.log: Logging initialized @4793ms to org.sparkproject.jetty.util.log.Slf4jLog\n",
            "23/04/15 06:01:25 INFO org.sparkproject.jetty.server.Server: jetty-9.4.40.v20210413; built: 2021-04-13T20:42:42.668Z; git: b881a572662e1943a14ae12e7e1207989f218b74; jvm 1.8.0_362-b09\n",
            "23/04/15 06:01:25 INFO org.sparkproject.jetty.server.Server: Started @4934ms\n",
            "23/04/15 06:01:25 INFO org.sparkproject.jetty.server.AbstractConnector: Started ServerConnector@762eec30{HTTP/1.1, (http/1.1)}{0.0.0.0:34819}\n",
            "23/04/15 06:01:26 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at bdma-m/10.138.0.31:8032\n",
            "23/04/15 06:01:26 INFO org.apache.hadoop.yarn.client.AHSProxy: Connecting to Application History server at bdma-m/10.138.0.31:10200\n",
            "23/04/15 06:01:28 INFO org.apache.hadoop.conf.Configuration: resource-types.xml not found\n",
            "23/04/15 06:01:28 INFO org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'resource-types.xml'.\n",
            "23/04/15 06:01:29 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1681538216158_0001\n",
            "23/04/15 06:01:30 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at bdma-m/10.138.0.31:8030\n",
            "23/04/15 06:01:33 INFO com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl: Ignoring exception of type GoogleJsonResponseException; verified object already exists with desired state.\n",
            "23/04/15 06:01:36 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input files to process : 1\n",
            "23/04/15 06:01:36 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input files to process : 1\n",
            "23/04/15 06:02:42 INFO com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystem: Successfully repaired 'gs://bdma/shared/2023_spring/HW3/24373710_Uddin/' directory.\n",
            "23/04/15 06:02:43 INFO org.sparkproject.jetty.server.AbstractConnector: Stopped Spark@762eec30{HTTP/1.1, (http/1.1)}{0.0.0.0:0}\n",
            "Completed\n",
            "Job [fbdf9c7d90ec4e5080259b35e88f4c2c] finished successfully.\n",
            "done: true\n",
            "driverControlFilesUri: gs://dataproc-staging-us-west1-901723776519-ddnkwogk/google-cloud-dataproc-metainfo/a199b803-8e6d-40e6-8f25-be0de8a8d5db/jobs/fbdf9c7d90ec4e5080259b35e88f4c2c/\n",
            "driverOutputResourceUri: gs://dataproc-staging-us-west1-901723776519-ddnkwogk/google-cloud-dataproc-metainfo/a199b803-8e6d-40e6-8f25-be0de8a8d5db/jobs/fbdf9c7d90ec4e5080259b35e88f4c2c/driveroutput\n",
            "jobUuid: e76308d4-7261-3768-9922-78b69d88554c\n",
            "placement:\n",
            "  clusterName: bdma\n",
            "  clusterUuid: a199b803-8e6d-40e6-8f25-be0de8a8d5db\n",
            "pysparkJob:\n",
            "  args:\n",
            "  - gs://bdma/data/complaints.csv\n",
            "  - gs://bdma/shared/2023_spring/HW3/24373710_Uddin\n",
            "  mainPythonFileUri: gs://dataproc-staging-us-west1-901723776519-ddnkwogk/google-cloud-dataproc-metainfo/a199b803-8e6d-40e6-8f25-be0de8a8d5db/jobs/fbdf9c7d90ec4e5080259b35e88f4c2c/staging/BDM_HW3_24373710_Uddin.py\n",
            "reference:\n",
            "  jobId: fbdf9c7d90ec4e5080259b35e88f4c2c\n",
            "  projectId: big-data-380022\n",
            "status:\n",
            "  state: DONE\n",
            "  stateStartTime: '2023-04-15T06:02:48.045333Z'\n",
            "statusHistory:\n",
            "- state: PENDING\n",
            "  stateStartTime: '2023-04-15T06:01:18.155966Z'\n",
            "- state: SETUP_DONE\n",
            "  stateStartTime: '2023-04-15T06:01:18.206854Z'\n",
            "- details: Agent reported job success\n",
            "  state: RUNNING\n",
            "  stateStartTime: '2023-04-15T06:01:18.533553Z'\n",
            "yarnApplications:\n",
            "- name: BDM_HW3_24373710_Uddin.py\n",
            "  progress: 1.0\n",
            "  state: FINISHED\n",
            "  trackingUrl: http://bdma-m:8088/proxy/application_1681538216158_0001/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gsutil ls gs://bdma/shared/2023_spring/HW3"
      ],
      "metadata": {
        "id": "rV888SYf8wEo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f1f9dca-1e70-4ad5-a155-7f52de5baa44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gs://bdma/shared/2023_spring/HW3/\n",
            "gs://bdma/shared/2023_spring/HW3/16141003_Olsen/\n",
            "gs://bdma/shared/2023_spring/HW3/24363838_Lau/\n",
            "gs://bdma/shared/2023_spring/HW3/24369480_Chandani/\n",
            "gs://bdma/shared/2023_spring/HW3/24373710_Uddin/\n",
            "gs://bdma/shared/2023_spring/HW3/24438996_Radaelli/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gsutil ls gs://bdma/shared/2023_spring/HW3/24373710_Uddin/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2BVOhlNxysJ",
        "outputId": "6078e05f-593e-44d4-c00a-46ca218c11a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gs://bdma/shared/2023_spring/HW3/24373710_Uddin/\n",
            "gs://bdma/shared/2023_spring/HW3/24373710_Uddin/_SUCCESS\n",
            "gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00000-fc38ba72-13b6-455c-8cbf-b98f2df80384-c000.csv\n",
            "gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00001-fc38ba72-13b6-455c-8cbf-b98f2df80384-c000.csv\n",
            "gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00002-fc38ba72-13b6-455c-8cbf-b98f2df80384-c000.csv\n",
            "gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00003-fc38ba72-13b6-455c-8cbf-b98f2df80384-c000.csv\n",
            "gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00004-fc38ba72-13b6-455c-8cbf-b98f2df80384-c000.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QFKDucrzgu5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !gsutil rm -r gs://bdma/shared/2023_spring/HW3/24373710_Uddin/"
      ],
      "metadata": {
        "id": "EfabZGb5wOrQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b6e066f-a550-4731-ab46-050668c4f523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/#1681537550695534...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/_SUCCESS#1681537550979022...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00000-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537527060904...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00001-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537527650720...\n",
            "/ [4 objects]                                                                   \n",
            "==> NOTE: You are performing a sequence of gsutil operations that may\n",
            "run significantly faster if you instead use gsutil -m rm ... Please\n",
            "see the -m section under \"gsutil help options\" for further information\n",
            "about when gsutil -m can be advantageous.\n",
            "\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00002-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537525605261...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00003-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537527060678...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00004-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537525613835...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00005-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537525796368...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00006-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537527353895...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00007-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537527658139...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00008-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537527344334...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00009-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537525803207...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00010-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537528775493...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00011-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537528834984...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00012-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537527655547...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00013-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537527770186...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00014-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537528830786...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00015-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537529249244...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00016-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537528822144...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00017-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537530244503...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00018-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537529699721...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00019-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537530234248...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00020-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537529426965...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00021-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537529390828...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00022-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537530324121...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00023-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537530739139...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00024-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537530812437...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00025-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537530321293...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00026-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537530922087...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00027-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537531830469...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00028-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537531265904...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00029-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537532104328...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00030-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537532237504...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00031-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537531762955...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00032-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537531802245...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00033-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537532368955...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00034-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537532763084...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00035-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537531770712...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00036-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537533514511...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00037-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537533112226...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00038-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537533673284...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00039-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537533843705...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00040-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537534222650...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00041-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537533232378...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00042-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537533330487...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00043-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537533276233...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00044-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537534860443...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00045-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537535049270...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00046-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537534508622...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00047-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537535272266...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00048-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537535605915...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00049-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537534583185...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00050-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537536299435...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00051-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537536537348...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00052-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537536608876...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00053-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537534630734...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00054-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537537086114...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00055-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537534698746...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00056-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537537681333...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00057-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537537943572...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00058-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537538115186...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00059-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537535925293...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00060-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537538523753...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00061-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537536022087...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00062-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537539108203...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00063-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537536129929...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00064-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537539338647...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00065-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537536192062...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00066-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537537275320...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00067-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537537400374...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00068-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537537518063...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00069-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537537569880...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00070-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537539530037...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00071-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537538556535...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00072-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537538682911...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00073-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537538852627...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00074-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537538843786...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00075-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537540001700...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00076-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537539830755...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00077-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537540490907...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00078-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537540899513...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00079-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537540852790...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00080-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537540042151...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00081-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537540168676...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00082-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537540175862...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00083-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537541328570...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00084-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537541160598...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00085-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537541832364...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00086-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537541432997...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00087-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537542286578...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00088-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537541554006...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00089-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537541554969...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00090-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537542687116...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00091-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537542769206...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00092-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537542279213...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00093-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537542449602...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00094-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537542849243...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00095-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537542941795...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00096-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537543960231...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00097-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537543294127...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00098-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537544127335...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00099-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537544178987...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00100-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537543621462...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00101-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537544223872...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00102-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537543681329...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00103-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537543786317...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00104-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537544627182...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00105-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537545074409...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00106-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537545095142...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00107-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537545258261...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00108-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537545381824...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00109-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537545492296...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00110-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537545178835...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00111-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537545596593...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00112-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537546012746...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00113-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537546658766...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00114-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537546664800...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00115-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537546406103...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00116-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537546495534...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00117-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537546468873...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00118-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537546893851...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00119-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537546951762...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00120-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537547893693...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00121-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537547336725...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00122-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537547940654...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00123-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537548232965...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00124-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537547775582...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00125-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537548359824...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00126-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537547842266...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00127-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537549197169...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00128-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537547831918...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00129-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537549270612...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00130-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537548640035...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00131-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537549199321...\n",
            "Removing gs://bdma/shared/2023_spring/HW3/24373710_Uddin/part-00132-50802079-6825-4993-bf8a-eb57ff1d4948-c000.csv#1681537549597294...\n",
            "/ [135 objects]  5.33 objects/s                                                 \n",
            "==> NOTE: You are performing a sequence of gsutil operations that may\n",
            "run significantly faster if you instead use gsutil -m rm ... Please\n",
            "see the -m section under \"gsutil help options\" for further information\n",
            "about when gsutil -m can be advantageous.\n",
            "\n",
            "\n",
            "Operation completed over 135 objects.                                            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORTANT: DELETE YOUR CLUSTER AFTER DONE"
      ],
      "metadata": {
        "id": "AuatPu7h9Rso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud dataproc clusters delete bdma -q\n",
        "!gcloud dataproc clusters list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRrjCGLS9N38",
        "outputId": "ec7ccf77-f507-49a3-a08d-83b83618be08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Waiting on operation [projects/big-data-380022/regions/us-west1/operations/5949efbe-adc7-3c66-9cd5-3ab382fff8be].\n",
            "Deleted [https://dataproc.googleapis.com/v1/projects/big-data-380022/regions/us-west1/clusters/bdma].\n",
            "Listed 0 items.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lrvL8Uni9N8j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}